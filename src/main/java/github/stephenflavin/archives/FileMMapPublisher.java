package github.stephenflavin.archives;

import static java.nio.channels.FileChannel.MapMode.READ_ONLY;
import static java.nio.file.StandardOpenOption.READ;

import java.io.IOException;
import java.nio.ByteBuffer;
import java.nio.channels.FileChannel;
import java.nio.file.Path;
import java.util.ArrayList;
import java.util.concurrent.Flow;
import java.util.stream.Stream;

/**
 * An implementation of {@link Flow.Publisher} that reads a file as {@link java.nio.MappedByteBuffer}s.
 * Unlike traditional a {@link java.util.concurrent.Flow.Subscription#request(long)} the subscription generated by this publisher treats the
 * requested number as <b>the number of chunks of the file to return in a single buffer</b> since subscribers are more likely to concerned
 * by the size of the {@link ByteBuffer} than the number of buffers, this respects the
 * <a href="https://github.com/reactive-streams/reactive-streams-jvm#1-publisher-code">reactive streams rules</a> spec.
 * <ol>
 *   <li>The total number of onNext´s signalled by a Publisher to a Subscriber MUST be <b>less than or equal to</b> the total number of
 *   elements requested by that Subscriber´s Subscription at all times.</li>
 *   <li>A Publisher MAY signal fewer onNext than requested and terminate the Subscription by calling onComplete or onError.</li>
 * </ol>
 */
public class FileMMapPublisher implements Flow.Publisher<FileMMapPublisher.FileChunk> {

    private final Path path;

    public FileMMapPublisher(Path path) {
        this.path = path;
    }

    @Override
    public void subscribe(Flow.Subscriber<? super FileChunk> subscriber) {
        try {
            subscriber.onSubscribe(new MMapSubscription(subscriber, path));
        } catch (Throwable ex) {
            subscriber.onError(ex);
        }
    }

    private static class MMapSubscription implements Flow.Subscription {
        private static final int OPTIMAL_READ_CHUNK_SIZE = 1024 * 256; // 256k
        private static final long maxRequested = Long.MAX_VALUE / (1024 * 256);

        private final Flow.Subscriber<? super FileChunk> subscriber;
        private final FileChannel fc;
        private final long fileSize;
        private long remaining;

        private MMapSubscription(Flow.Subscriber<? super FileChunk> subscriber,
                                 Path path) throws IOException {
            this.fc = FileChannel.open(path, READ);
            this.subscriber = subscriber;
            this.fileSize = fc.size();
            this.remaining = fc.size();
            if (fileSize == 0) {
                subscriber.onComplete();
            }
        }

        @Override
        public synchronized void request(long requested) {
            if (remaining == 0) {
                return;
            }
            var currentOffset = fileSize - remaining;
            try {
                var toRead = Math.min(Math.min(requested, maxRequested) * OPTIMAL_READ_CHUNK_SIZE, remaining);
                remaining -= toRead;

                // the last chunk which is < OPTIMAL_READ_CHUNK_SIZE will be published by the previous chunk
                if (remaining < OPTIMAL_READ_CHUNK_SIZE) {
                    toRead += remaining;
                    remaining = 0;
                }

                toBuffers(currentOffset, toRead).forEach(subscriber::onNext);
                if (remaining == 0) {
                    subscriber.onComplete();
                    fc.close();
                }
            } catch (IOException e) {
                subscriber.onError(e);
                try {
                    fc.close();
                } catch (IOException ex) {
                    // ignore
                }
            }
        }

        private Stream<FileChunk> toBuffers(long currentOffset, long bytesToRead) throws IOException {
            // todo experiment with ExtendedMapMode.READ_ONLY_SYNC
            if (bytesToRead < Integer.MAX_VALUE) {
                return Stream.of(new FileChunk(Math.max(1, Math.floorDiv(bytesToRead, OPTIMAL_READ_CHUNK_SIZE)),
                        fc.map(READ_ONLY, currentOffset, bytesToRead)));
            }

            var finalOffset = currentOffset + bytesToRead;
            var chunks = Math.floorDiv(bytesToRead, OPTIMAL_READ_CHUNK_SIZE);
            var numBuffers = Math.ceilDiv(bytesToRead, Integer.MAX_VALUE);
            var chunksPerBuffer = Math.floorDiv(chunks, numBuffers);
            var bytesPerBuffer = chunksPerBuffer * OPTIMAL_READ_CHUNK_SIZE;

            var fileChunks = new ArrayList<FileChunk>((int) numBuffers);
            while (currentOffset != finalOffset) {
                chunks -= chunksPerBuffer;
                if (chunks < chunksPerBuffer) {
                    bytesPerBuffer = finalOffset - currentOffset;
                    chunksPerBuffer += chunks;
                    chunks = 0;
                }
                fileChunks.add(new FileChunk(chunksPerBuffer,
                        fc.map(READ_ONLY, currentOffset, bytesPerBuffer)));
                currentOffset += bytesPerBuffer;
            }
            return fileChunks.stream();
        }

        @Override
        public void cancel() {
            remaining = 0;
            try {
                fc.close();
            } catch (IOException e) {
                subscriber.onError(e);
            }
        }
    }

    public record FileChunk(long numChunks, ByteBuffer buffer) {
    }
}
